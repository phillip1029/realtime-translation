<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Broadcaster | Realtime Translator</title>
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, sans-serif; margin:0; padding:24px; background:#0b1021; color:#f4f4f8; }
    .card { background: rgba(255,255,255,0.06); border:1px solid rgba(255,255,255,0.08); border-radius:16px; padding:20px; max-width:960px; margin:auto; box-shadow:0 20px 50px rgba(0,0,0,0.3); }
    h1 { margin:0 0 8px; letter-spacing:0.02em; }
    .status { margin-bottom:12px; color:#a6b1d8; }
    label { display:block; margin-bottom:8px; }
    select, input, button { font-size:15px; padding:10px 12px; border-radius:10px; border:1px solid rgba(255,255,255,0.2); background:rgba(255,255,255,0.08); color:#f4f4f8; width:100%; }
    button { cursor:pointer; background:linear-gradient(135deg,#6a9bff,#9c6bff); border:none; color:#0b1021; font-weight:700; transition:transform 0.08s ease, box-shadow 0.2s ease; }
    button:active { transform:translateY(1px); box-shadow:none; }
    .grid { display:grid; gap:16px; grid-template-columns:repeat(auto-fit,minmax(220px,1fr)); margin-bottom:16px; }
    .row { display:flex; gap:12px; align-items:center; }
    .row label { margin:0; }
    .log { background:rgba(255,255,255,0.04); border-radius:12px; padding:12px 14px; max-height:260px; overflow-y:auto; border:1px solid rgba(255,255,255,0.08); }
    .log-entry { margin-bottom:12px; }
    .badge { display:inline-block; padding:2px 8px; border-radius:8px; background:rgba(255,255,255,0.12); color:#c5d7ff; font-size:12px; margin-bottom:4px; }
    .controls { display:flex; gap:8px; align-items:center; flex-wrap:wrap; margin-top:6px; }
    .controls label { margin:0; display:flex; align-items:center; gap:6px; font-size:13px; color:#c5c8d8; }
    .controls input[type="range"] { width:120px; }
    .stack { background:rgba(255,255,255,0.04); border:1px solid rgba(255,255,255,0.08); border-radius:12px; padding:10px 12px; margin:12px 0; }
    .stack h3 { margin:0 0 8px; font-size:15px; color:#c5d7ff; }
    .stack div { max-height:160px; min-height:48px; padding:6px 4px; overflow-y:auto; white-space:pre-wrap; }
  </style>
</head>
<body>
  <div class="card">
    <h1>Realtime Audio Translator · Broadcaster</h1>
    <p class="status" id="status">Idle</p>

    <div class="grid">
      <label>
        Source language (hint for Whisper)
        <input id="sourceLang" placeholder="auto-detect if empty e.g. en, es, fr" />
      </label>
      <label>
        Room / session ID
        <input id="roomName" placeholder="default" value="default" />
      </label>
      <label>
        Passcode (required)
        <input id="roomPasscode" placeholder="set a passcode" />
      </label>
      <label>
        Target languages (multi-select)
        <select id="targetLangs" multiple size="6">
          <option value="English" selected>English</option>
          <option value="Spanish" selected>Spanish</option>
          <option value="French">French</option>
          <option value="German">German</option>
          <option value="Portuguese">Portuguese</option>
          <option value="Japanese">Japanese</option>
          <option value="Korean">Korean</option>
          <option value="Arabic">Arabic</option>
          <option value="Hindi">Hindi</option>
          <option value="Mandarin Chinese">Mandarin Chinese</option>
          <option value="Cantonese">Cantonese</option>
        </select>
      </label>
      <label>
        Output mode
        <select id="outputMode">
          <option value="text">Text only</option>
          <option value="audio">Audio only</option>
          <option value="both">Text + Audio</option>
        </select>
      </label>
      <label>
        Monitor language (autoplay only this)
        <select id="monitorLang"></select>
      </label>
      <label>
        Audio source
        <select id="audioSource">
          <option value="mic" selected>Microphone</option>
          <option value="tab">Browser tab audio (e.g. YouTube)</option>
        </select>
        <small style="color:#a6b1d8;">For tab audio, pick the tab with sound when prompted.</small>
      </label>
    </div>

    <div class="row" style="margin-bottom:12px;">
      <button id="toggleBtn" style="width:200px;">Start capturing</button>
      <span id="latency" class="status">Waiting for audio…</span>
    </div>

    <div class="stack">
      <h3>Live transcript (all)</h3>
      <div id="liveTranscript" aria-live="polite"></div>
    </div>
    <div class="stack">
      <h3>Live translation (monitor language)</h3>
      <div id="liveTranslation" aria-live="polite"></div>
    </div>
    <div class="stack">
      <h3>Continuous audio stream (monitor language)</h3>
      <audio id="streamAudio" controls style="width:100%;"></audio>
      <div id="queueStatus" class="status" style="margin-top:6px;">Queue: empty</div>
    </div>
    <div class="stack">
      <h3>Downloads</h3>
      <div class="grid" style="grid-template-columns:repeat(auto-fit,minmax(200px,1fr));">
        <label>
          Language for downloads
          <select id="downloadLang"></select>
        </label>
        <div class="row" style="align-items:flex-start;">
          <button id="downloadTranscript">Download transcript</button>
        </div>
        <div class="row" style="align-items:flex-start;">
          <button id="downloadTranslation">Download translation</button>
        </div>
        <div class="row" style="align-items:flex-start;">
          <button id="downloadAudio">Download audio</button>
        </div>
      </div>
    </div>

    <div class="stack">
      <h3>Session usage</h3>
      <div class="grid" style="grid-template-columns:repeat(auto-fit,minmax(160px,1fr));">
        <div><div class="badge">Model</div><div id="usageModel">-</div></div>
        <div><div class="badge">Prompt tokens</div><div id="usagePrompt">0</div></div>
        <div><div class="badge">Completion tokens</div><div id="usageCompletion">0</div></div>
        <div><div class="badge">Total tokens</div><div id="usageTotal">0</div></div>
        <div><div class="badge">Est. cost (USD)</div><div id="usageCost">0</div></div>
      </div>
    </div>

    <div class="log" id="log" style="display:none;"></div>
  </div>

  <script>
    const statusEl = document.getElementById('status');
    const logEl = document.getElementById('log');
    const toggleBtn = document.getElementById('toggleBtn');
    const targetLangsEl = document.getElementById('targetLangs');
    const sourceLangEl = document.getElementById('sourceLang');
    const roomNameEl = document.getElementById('roomName');
    const roomPasscodeEl = document.getElementById('roomPasscode');
    const outputModeEl = document.getElementById('outputMode');
    const monitorLangEl = document.getElementById('monitorLang');
    const audioSourceEl = document.getElementById('audioSource');
    const latencyEl = document.getElementById('latency');
    const liveTranscriptEl = document.getElementById('liveTranscript');
    const liveTranslationEl = document.getElementById('liveTranslation');
    const streamAudioEl = document.getElementById('streamAudio');
    const queueStatusEl = document.getElementById('queueStatus');
    const downloadTranscriptBtn = document.getElementById('downloadTranscript');
    const downloadTranslationBtn = document.getElementById('downloadTranslation');
    const downloadAudioBtn = document.getElementById('downloadAudio');
    const downloadLangEl = document.getElementById('downloadLang');
    const usageModelEl = document.getElementById('usageModel');
    const usagePromptEl = document.getElementById('usagePrompt');
    const usageCompletionEl = document.getElementById('usageCompletion');
    const usageTotalEl = document.getElementById('usageTotal');
    const usageCostEl = document.getElementById('usageCost');

    let mediaRecorder = null;
    let audioStream = null;
    let chunkTimer = null;
    const chunkMs = 3000;
    let isRecording = false;
    let queue = Promise.resolve();
    const audioSettings = new Map(); // language -> { userMuted, volume }
    const audioRegistry = new Map(); // language -> Set<HTMLAudioElement>
    let rollingTranscript = '';
    const liveState = { transcript: '', translation: '' };
    let playbackQueue = [];
    let currentUrl = null;
    let transcriptParts = [];
    const translationPartsByLang = new Map();
    const audioChunksByLang = new Map();

    const pickMimeType = () => {
      const candidates = [
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/ogg;codecs=opus',
        'audio/ogg',
      ];
      for (const type of candidates) {
        if (window.MediaRecorder && MediaRecorder.isTypeSupported(type)) return type;
      }
      return '';
    };

    const channelName = (room, language) => `${room || 'default'}:${(language || '').toLowerCase()}`;

    const ensureSettings = (language) => {
      if (!audioSettings.has(language)) {
        audioSettings.set(language, { userMuted: language !== monitorLangEl.value, volume: 0.8 });
      }
      return audioSettings.get(language);
    };

    const registerAudio = (language, el) => {
      if (!audioRegistry.has(language)) audioRegistry.set(language, new Set());
      audioRegistry.get(language).add(el);
      el.addEventListener('ended', () => audioRegistry.get(language)?.delete(el));
    };

    const applyAudioSettings = (language) => {
      const settings = ensureSettings(language);
      const effectiveMuted = language !== monitorLangEl.value || settings.userMuted;
      const set = audioRegistry.get(language);
      if (!set) return;
      set.forEach((el) => {
        el.muted = effectiveMuted;
        el.volume = settings.volume;
      });
    };

    const applyAllAudioSettings = () => {
      audioRegistry.forEach((_, lang) => applyAudioSettings(lang));
    };

    const updateLiveText = () => {
      liveTranscriptEl.textContent = liveState.transcript.trim();
      liveTranslationEl.textContent = liveState.translation.trim();
      liveTranscriptEl.scrollTop = liveTranscriptEl.scrollHeight;
      liveTranslationEl.scrollTop = liveTranslationEl.scrollHeight;
    };

    const updateQueueStatus = () => {
      queueStatusEl.textContent = `Queue: ${playbackQueue.length}${streamAudioEl.paused ? ' (paused)' : ' (playing)'}`;
    };

    const revokeCurrent = () => {
      if (currentUrl) {
        URL.revokeObjectURL(currentUrl);
        currentUrl = null;
      }
    };

    const playNext = () => {
      revokeCurrent();
      const next = playbackQueue.shift();
      if (!next) {
        streamAudioEl.removeAttribute('src');
        streamAudioEl.load();
        updateQueueStatus();
        return;
      }
      currentUrl = next;
      streamAudioEl.src = next;
      streamAudioEl.play().catch(() => {});
      updateQueueStatus();
    };

    streamAudioEl.addEventListener('ended', playNext);

    const enqueueAudio = (base64) => {
      if (!base64) return;
      const binary = atob(base64);
      const len = binary.length;
      const bytes = new Uint8Array(len);
      for (let i = 0; i < len; i++) bytes[i] = binary.charCodeAt(i);
      const blob = new Blob([bytes], { type: 'audio/mpeg' });
      const url = URL.createObjectURL(blob);
      playbackQueue.push(url);
      if (streamAudioEl.paused && playbackQueue.length === 1) {
        playNext();
      } else {
        updateQueueStatus();
      }
    };

    const resetStream = () => {
      playbackQueue.forEach((u) => URL.revokeObjectURL(u));
      playbackQueue = [];
      revokeCurrent();
      streamAudioEl.pause();
      streamAudioEl.removeAttribute('src');
      streamAudioEl.load();
      updateQueueStatus();
    };

    const syncMonitorOptions = () => {
      const langs = Array.from(targetLangsEl.options).map((o) => o.value);
      const current = monitorLangEl.value;
      monitorLangEl.innerHTML = '';
      downloadLangEl.innerHTML = '';
      langs.forEach((lang) => {
        const opt = document.createElement('option');
        opt.value = lang;
        opt.textContent = lang;
        monitorLangEl.appendChild(opt);
        const opt2 = opt.cloneNode(true);
        downloadLangEl.appendChild(opt2);
      });
      if (langs.includes(current)) {
        monitorLangEl.value = current;
      } else {
        monitorLangEl.value = langs[0] || '';
      }
      if (!downloadLangEl.value && langs.length) downloadLangEl.value = langs[0];
      applyAllAudioSettings();
      resetStream();
    };

    const appendLog = (transcript, results, meta = {}) => {
      const container = document.createElement('div');
      container.className = 'log-entry';
      const time = new Date().toLocaleTimeString();
      const transcriptEl = transcript ? `<div><span class="badge">Transcript</span><div>${transcript}</div></div>` : '';
      const header = meta.channel ? `${time} · ${meta.channel}` : time;
      container.innerHTML = `<div class="status">${header}</div>${transcriptEl}`;

      (results || []).forEach(({ language, translation, audioBase64 }) => {
        const block = document.createElement('div');
        block.innerHTML = `<div><span class="badge">${language}</span><div>${translation || ''}</div></div>`;
        if (audioBase64) {
          const audio = document.createElement('audio');
          audio.controls = true;
          audio.src = `data:audio/mpeg;base64,${audioBase64}`;
          const settings = ensureSettings(language);
          registerAudio(language, audio);
          applyAudioSettings(language);
          // Autoplay only if this is the monitored language and not muted.
          if (language === monitorLangEl.value && !settings.userMuted && !audio.muted) {
            audio.play().catch(() => {});
          }
          // For continuous stream, enqueue only monitored language.
          // Store per-language assets
          if (translation) {
            if (!translationPartsByLang.has(language)) translationPartsByLang.set(language, []);
            translationPartsByLang.get(language).push(translation);
          }
          if (audioBase64) {
            const binary = atob(audioBase64);
            const len = binary.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) bytes[i] = binary.charCodeAt(i);
            const blob = new Blob([bytes], { type: 'audio/mpeg' });
            if (!audioChunksByLang.has(language)) audioChunksByLang.set(language, []);
            audioChunksByLang.get(language).push(blob);
          }

          if (language === monitorLangEl.value) {
            enqueueAudio(audioBase64);
            if (translation) {
              liveState.translation += (liveState.translation ? '\n' : '') + translation;
            }
            if (transcript) {
              liveState.transcript += (liveState.transcript ? '\n' : '') + transcript;
            }
            updateLiveText();
          }
          const controls = document.createElement('div');
          controls.className = 'controls';
          const muteId = `mute-${language}-${Date.now()}`;
          const volumeId = `vol-${language}-${Date.now()}`;
          controls.innerHTML = `
            <label><input type="checkbox" id="${muteId}" ${settings.userMuted ? 'checked' : ''}/> Mute</label>
            <label>Vol <input type="range" id="${volumeId}" min="0" max="1" step="0.05" value="${settings.volume}"></label>
          `;
          block.appendChild(audio);
          block.appendChild(controls);

          controls.querySelector(`#${muteId}`).addEventListener('change', (e) => {
            settings.userMuted = e.target.checked;
            applyAudioSettings(language);
          });
          controls.querySelector(`#${volumeId}`).addEventListener('input', (e) => {
            settings.volume = Number(e.target.value);
            applyAudioSettings(language);
          });
        }
        container.appendChild(block);
      });

      logEl.prepend(container);
    };

    const updateStatus = (text) => {
      statusEl.textContent = text;
    };

    const hasAudibleAudio = async (blob) => {
      if (!blob || !blob.size) return false;
      try {
        const arrayBuffer = await blob.arrayBuffer();
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        const decoded = await audioCtx.decodeAudioData(arrayBuffer.slice(0));
        const channelData = decoded.getChannelData(0);
        let sum = 0;
        const len = channelData.length;
        for (let i = 0; i < len; i++) {
          const v = channelData[i];
          sum += v * v;
        }
        const rms = Math.sqrt(sum / len);
        audioCtx.close().catch(() => {});
        return rms > 0.005; // simple energy gate
      } catch (err) {
        console.warn('Audio analysis failed, sending anyway', err);
        return true;
      }
    };

    const acquireAudioStream = async () => {
      const source = audioSourceEl.value;
      if (source === 'tab') {
        const displayStream = await navigator.mediaDevices.getDisplayMedia({ audio: true, video: true });
        const audioTrack = displayStream.getAudioTracks()[0];
        if (!audioTrack) {
          displayStream.getTracks().forEach((t) => t.stop());
          throw new Error('No audio track captured from tab.');
        }
        displayStream.getVideoTracks().forEach((t) => t.stop());
        return new MediaStream([audioTrack]);
      }
      return navigator.mediaDevices.getUserMedia({ audio: true });
    };

    const sendChunk = async (blob) => {
      if (!blob || blob.size < 200) return;
      const audible = await hasAudibleAudio(blob);
      if (!audible) {
        latencyEl.textContent = 'Silence skipped';
        return;
      }
      const targetLangs = Array.from(targetLangsEl.selectedOptions).map((o) => o.value);
      const sourceLang = sourceLangEl.value.trim();
      const room = roomNameEl.value.trim() || 'default';
      const passcode = roomPasscodeEl.value.trim();
      const outputMode = outputModeEl.value;
      const start = performance.now();
      const contextSlice = rollingTranscript.slice(-600); // send recent context for coherence
      const params = new URLSearchParams({ outputMode, room, passcode, context: contextSlice });
      targetLangs.forEach((lang) => params.append('targetLang', lang));
      if (sourceLang) params.set('sourceLang', sourceLang);

      const contentType = blob.type || 'application/octet-stream';

      const resp = await fetch(`/api/translate-audio?${params.toString()}`, {
        method: 'POST',
        headers: {
          'Content-Type': contentType,
          'X-Audio-Mime-Type': contentType,
        },
        body: blob,
      });

      if (!resp.ok) {
        const err = await resp.text();
        throw new Error(err || 'Translation failed');
      }

      const json = await resp.json();
      const elapsed = Math.round(performance.now() - start);
      latencyEl.textContent = `Chunk processed in ${elapsed} ms`;
      if (json.transcript) {
        rollingTranscript += (rollingTranscript ? '\n' : '') + json.transcript;
        transcriptParts.push(json.transcript);
      }
      appendLog(json.transcript, json.results, { channel: room });
      if (json.usage) {
        usageModelEl.textContent = json.usage.model || 'N/A';
        usagePromptEl.textContent = json.usage.prompt_tokens ?? 0;
        usageCompletionEl.textContent = json.usage.completion_tokens ?? 0;
        usageTotalEl.textContent = json.usage.total_tokens ?? 0;
        usageCostEl.textContent = json.usage.cost ?? 0;
      }
    };

    const startChunkRecorder = () => {
      if (!audioStream) return;

      const mimeType = pickMimeType();
      mediaRecorder = mimeType ? new MediaRecorder(audioStream, { mimeType }) : new MediaRecorder(audioStream);

      mediaRecorder.ondataavailable = (e) => {
        if (!e.data || !e.data.size) return;
        queue = queue
          .then(() => sendChunk(e.data))
          .catch((err) => {
            console.error(err);
            updateStatus('Error sending audio chunk. Check console.');
          });
      };

      mediaRecorder.onstop = () => {
        if (chunkTimer) {
          clearTimeout(chunkTimer);
          chunkTimer = null;
        }

        if (isRecording) {
          startChunkRecorder();
          return;
        }

        if (audioStream) {
          audioStream.getTracks().forEach((t) => t.stop());
          audioStream = null;
        }

        queue.catch(() => {}).finally(() => updateStatus('Stopped'));
      };

      mediaRecorder.start();
      chunkTimer = setTimeout(() => {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
          mediaRecorder.stop();
        }
      }, chunkMs);
    };

    const startRecording = async () => {
      queue = Promise.resolve();
      latencyEl.textContent = 'Waiting for audio…';
      syncMonitorOptions();
      resetStream();
      liveState.transcript = '';
      liveState.translation = '';
      rollingTranscript = '';
      transcriptParts = [];
      translationPartsByLang.clear();
      audioChunksByLang.clear();
      updateLiveText();
      audioStream = await acquireAudioStream();
      isRecording = true;
      toggleBtn.textContent = 'Stop capturing';
      updateStatus('Capturing…');
      startChunkRecorder();
    };

    const stopRecording = async () => {
      isRecording = false;
      if (chunkTimer) {
        clearTimeout(chunkTimer);
        chunkTimer = null;
      }
      if (mediaRecorder) {
        try {
          if (mediaRecorder.state === 'recording') {
            // Ensure the final dataavailable fires.
            mediaRecorder.requestData?.();
            mediaRecorder.stop();
          }
        } catch (_) {}
      }
      toggleBtn.textContent = 'Start capturing';
      updateStatus('Stopping…');
      // Wait for any pending sends to finish so final chunk is delivered.
      await queue.catch(() => {});
      updateStatus('Stopped');
    };

    toggleBtn.addEventListener('click', async () => {
      if (isRecording) {
        await stopRecording();
        return;
      }
      try {
        await startRecording();
      } catch (error) {
        console.error(error);
        updateStatus('Microphone permission denied or not available.');
      }
    });

    targetLangsEl.addEventListener('change', () => {
      syncMonitorOptions();
    });

    monitorLangEl.addEventListener('change', () => {
      resetStream();
      liveState.translation = '';
      updateLiveText();
      applyAllAudioSettings();
    });

    const triggerDownload = (blob, filename) => {
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = filename;
      document.body.appendChild(a);
      a.click();
      a.remove();
      setTimeout(() => URL.revokeObjectURL(url), 1000);
    };

    downloadTranscriptBtn.addEventListener('click', () => {
      if (!transcriptParts.length) return alert('No transcript yet.');
      const text = transcriptParts.join('\n');
      const room = (roomNameEl.value.trim() || 'room').replace(/\s+/g, '_');
      triggerDownload(new Blob([text], { type: 'text/plain;charset=utf-8' }), `${room}-transcript.txt`);
    });

    downloadTranslationBtn.addEventListener('click', () => {
      const lang = downloadLangEl.value;
      const parts = translationPartsByLang.get(lang) || [];
      if (!parts.length) return alert('No translation for this language yet.');
      const room = (roomNameEl.value.trim() || 'room').replace(/\s+/g, '_');
      const langSlug = (lang || 'lang').replace(/\s+/g, '_');
      triggerDownload(new Blob([parts.join('\n')], { type: 'text/plain;charset=utf-8' }), `${room}-${langSlug}-translation.txt`);
    });

    downloadAudioBtn.addEventListener('click', () => {
      const lang = downloadLangEl.value;
      const chunks = audioChunksByLang.get(lang) || [];
      if (!chunks.length) return alert('No audio for this language yet.');
      const room = (roomNameEl.value.trim() || 'room').replace(/\s+/g, '_');
      const langSlug = (lang || 'lang').replace(/\s+/g, '_');
      triggerDownload(new Blob(chunks, { type: 'audio/mpeg' }), `${room}-${langSlug}-audio.mp3`);
    });

    // initialize monitor options on load
    syncMonitorOptions();
  </script>
</body>
</html>
